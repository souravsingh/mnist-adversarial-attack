# Adversarial Attacks on MNIST


This is an example of generating adversarial examples to exploit the deep MNIST Convolution network. It is inspired from It is inspired from [Intriguing Properties of Neural Networks](http://arxiv.org/abs/1312.6199), [Explaining and Harnessing Adversarial Examples](https://arxiv.org/abs/1412.6572)
and [Breaking Convnets](http://karpathy.github.io/2015/03/30/breaking-convnets/).  

## Running the code
To run the code, go to the link -
https://colab.research.google.com/github/souravsingh/mnist-adversarial-attack/blob/master/Keras_MNIST_attack.ipynb

The link contains the contents present in the notebook.Make sure to change your runtime to GPU so as to ensure that training is faster.

